#!/usr/bin/env python3
"""
Comprehensive Star Manipulation Detection Tool
Usage: python3 final.py <owner> <repo>
"""
import sys
import os
import re
import requests
import time
from datetime import datetime
from collections import Counter, defaultdict
import numpy as np
from scipy.cluster.hierarchy import linkage, fcluster
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import json
from dotenv import load_dotenv

load_dotenv()
TOKEN = os.getenv('GITHUB_TOKEN')
if not TOKEN:
    print("Error: GITHUB_TOKEN not found in .env file")
    sys.exit(1)

HEADERS = {"Authorization": f"token {TOKEN}"}
STAR_HEADERS = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3.star+json"}

def get_total_count_from_search(owner, repo, item_type):
    """Get accurate total count using GitHub Search API"""
    query = f"repo:{owner}/{repo} type:{item_type}"
    url = "https://api.github.com/search/issues"
    
    try:
        r = requests.get(url, headers=HEADERS, params={"q": query, "per_page": 1})
        if r.status_code == 200:
            return r.json().get('total_count', 0)
        else:
            print(f"   âš ï¸  Search API error for {item_type}: {r.status_code}")
            return 0
    except Exception as e:
        print(f"   âš ï¸  Error counting {item_type}: {e}")
        return 0

def create_visualization(owner, repo, report_data):
    """Create 4-panel visualization"""
    print(f"\n[7/8] Creating visualization...")
    
    metrics = report_data['metrics']
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle(f'Star Manipulation Analysis - {owner}/{repo}', 
                 fontsize=16, fontweight='bold')
    
    # Panel 1: Metrics Bar Chart
    ax1 = axes[0, 0]
    metric_names = ['Fork Rate\n(%)', 'Issue Rate\n(%)', 'PR Rate\n(%)', 'Bot Commits\n(%)']
    metric_values = [
        metrics['fork_rate'],
        metrics['issue_rate'],
        metrics['pr_rate'],
        metrics['bot_commit_ratio']
    ]
    colors = ['red' if v < 8 else 'green' for v in [metric_values[0]]] + \
             ['red' if v < 2 else 'green' for v in metric_values[1:3]] + \
             ['red' if v > 50 else 'green' for v in [metric_values[3]]]
    
    bars = ax1.bar(metric_names, metric_values, color=colors, alpha=0.7, edgecolor='black')
    ax1.set_ylabel('Percentage (%)')
    ax1.set_title('Key Metrics Comparison')
    ax1.axhline(y=8, color='orange', linestyle='--', alpha=0.5, label='Fork threshold')
    ax1.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='Bot threshold')
    ax1.legend(fontsize=8)
    ax1.grid(True, alpha=0.3, axis='y')
    
    # Add value labels on bars
    for bar, val in zip(bars, metric_values):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.1f}%', ha='center', va='bottom', fontsize=9)
    
    # Panel 2: Clustering Info
    ax2 = axes[0, 1]
    ax2.axis('off')
    
    if 'main_cluster' in metrics and metrics['main_cluster']:
        cluster = metrics['main_cluster']
        cluster_text = f"""
Time Clustering Analysis
{'='*30}

Main Cluster Statistics:
  â€¢ Size: {cluster['count']} samples
  â€¢ Percentage: {cluster['percentage']:.1f}%
  â€¢ Mean Interval: {cluster['mean']:.1f} min
  â€¢ Std Deviation: {cluster['std']:.1f} min

Interpretation:
  {'ğŸ”´ CRITICAL' if cluster['std'] < 5 else 'ğŸŸ¢ NORMAL'}
  
  {'Standard deviation < 5 minutes' if cluster['std'] < 5 else 'Normal variation pattern'}
  {'indicates automated behavior!' if cluster['std'] < 5 else ''}
  
  {'Human behavior typically shows' if cluster['std'] < 5 else ''}
  {'std > 50 minutes' if cluster['std'] < 5 else ''}
        """
    else:
        cluster_text = "\n\nInsufficient data for\nclustering analysis"
    
    ax2.text(0.1, 0.5, cluster_text, fontsize=10, family='monospace',
            verticalalignment='center')
    
    # Panel 3: Score Breakdown
    ax3 = axes[1, 0]
    evidence = report_data['evidence_scores']
    categories = ['Issue\nRate', 'PR\nRate', 'Fork\nRate', 'Bot\nCommits', 'Time\nCluster', 'Bulk\nCreate']
    scores = [
        evidence['issue_rate'],
        evidence['pr_rate'],
        evidence['fork_rate'],
        evidence['bot_commits'],
        evidence['time_clustering'],
        evidence['bulk_creation']
    ]
    max_scores = [30, 20, 25, 30, 50, 25]
    
    x = np.arange(len(categories))
    width = 0.35
    
    bars1 = ax3.bar(x - width/2, scores, width, label='Actual Score', 
                   color='red', alpha=0.7, edgecolor='black')
    bars2 = ax3.bar(x + width/2, max_scores, width, label='Max Score',
                   color='lightgray', alpha=0.5, edgecolor='black')
    
    ax3.set_ylabel('Score')
    ax3.set_title('Evidence Score Breakdown')
    ax3.set_xticks(x)
    ax3.set_xticklabels(categories, fontsize=9)
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')
    
    # Panel 4: Summary
    ax4 = axes[1, 1]
    ax4.axis('off')
    
    total_score = report_data['suspicion_score']
    max_score = report_data['max_score']
    status = report_data['status']
    
    summary_text = f"""
ANALYSIS SUMMARY
{'='*40}

Repository: {owner}/{repo}
Analysis Date: {report_data['analysis_date'][:10]}

Stars: {metrics['stars']}
Forks: {metrics['forks']} ({metrics['fork_rate']:.1f}%)
Issues: {metrics['total_issues']} ({metrics['issue_rate']:.2f}%)
PRs: {metrics['total_prs']} ({metrics['pr_rate']:.2f}%)

SUSPICION SCORE: {total_score}/{max_score}
STATUS: {status}

Evidence Summary:
  â€¢ Issue Rate: {'FAIL' if evidence['issue_rate'] > 0 else 'PASS'}
  â€¢ PR Rate: {'FAIL' if evidence['pr_rate'] > 0 else 'PASS'}
  â€¢ Fork Rate: {'FAIL' if evidence['fork_rate'] > 0 else 'PASS'}
  â€¢ Bot Commits: {'FAIL' if evidence['bot_commits'] > 0 else 'PASS'}
  â€¢ Time Clustering: {'FAIL' if evidence['time_clustering'] > 0 else 'PASS'}
  â€¢ Bulk Creation: {'FAIL' if evidence['bulk_creation'] > 0 else 'PASS'}
    """
    
    ax4.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',
            verticalalignment='center')
    
    plt.tight_layout()
    
    output_file = f"visualization_{owner}_{repo}.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   âœ“ Saved: {output_file}")
    plt.close()

def generate_verdict(owner, repo, report_data):
    """Generate detailed verdict markdown file"""
    print(f"\n[8/8] Generating verdict document...")
    
    metrics = report_data['metrics']
    evidence = report_data['evidence_scores']
    total_score = report_data['suspicion_score']
    status = report_data['status']
    
    # Determine verdict level
    if total_score >= 100:
        verdict_level = "ğŸ”´ CONFIRMED MANIPULATION"
        confidence = "æé«˜"
    elif total_score >= 60:
        verdict_level = "ğŸ”´ HIGH SUSPICION"
        confidence = "é«˜"
    elif total_score >= 30:
        verdict_level = "ğŸŸ¡ MEDIUM SUSPICION"
        confidence = "ä¸­"
    else:
        verdict_level = "ğŸŸ¢ LOW SUSPICION"
        confidence = "ä½"
    
    verdict_md = f"""# åˆ†ææŠ¥å‘Š - {owner}/{repo}

> **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ¯ æœ€ç»ˆåˆ¤å†³

### å¯ç–‘åº¦è¯„åˆ†: **{total_score}/{report_data['max_score']}**

### åˆ¤å®šç»“æœ: **{verdict_level}**

### ç½®ä¿¡åº¦: **{confidence}**

---

## ğŸ“Š åŸºç¡€æ•°æ®

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| Stars | {metrics['stars']} | - |
| Forks | {metrics['forks']} ({metrics['fork_rate']:.1f}%) | {'ğŸ”´' if metrics['fork_rate'] < 8 else 'ğŸŸ¢'} |
| Issues | {metrics['total_issues']} ({metrics['issue_rate']:.2f}%) | {'ğŸ”´' if metrics['issue_rate'] < 2 else 'ğŸŸ¢'} |
| PRs | {metrics['total_prs']} ({metrics['pr_rate']:.2f}%) | {'ğŸ”´' if metrics['pr_rate'] < 2 else 'ğŸŸ¢'} |
| Bot Commits | {metrics['bot_commit_ratio']:.0f}% | {'ğŸ”´' if metrics['bot_commit_ratio'] > 50 else 'ğŸŸ¢'} |

---

## ğŸ” è¯æ®è¯¦æƒ…

### 1. Issueç‡åˆ†æ ({evidence['issue_rate']} åˆ†)

- **å®é™…å€¼**: {metrics['issue_rate']:.2f}%
- **æ­£å¸¸å€¼**: >2%
- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - Issueç‡è¿‡ä½' if evidence['issue_rate'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: Issueç‡<1%è¯´æ˜ç”¨æˆ·åªæ”¶è—ä¸ä½¿ç”¨ï¼Œå…¸å‹çš„è™šå‡starç‰¹å¾ã€‚' if evidence['issue_rate'] >= 30 else '**è¯´æ˜**: Issueç‡æ­£å¸¸ï¼Œç”¨æˆ·æœ‰çœŸå®åé¦ˆã€‚' if evidence['issue_rate'] == 0 else '**è¯´æ˜**: Issueç‡ç•¥ä½ï¼Œéœ€å…³æ³¨ã€‚'}

### 2. PRç‡åˆ†æ ({evidence['pr_rate']} åˆ†)

- **å®é™…å€¼**: {metrics['pr_rate']:.2f}%
- **æ­£å¸¸å€¼**: >2%
- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - PRç‡è¿‡ä½' if evidence['pr_rate'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: å‡ ä¹æ— PRè¯´æ˜é¡¹ç›®æ— äººè´¡çŒ®ï¼Œç¼ºä¹çœŸå®ç”¨æˆ·å‚ä¸ã€‚' if evidence['pr_rate'] >= 20 else '**è¯´æ˜**: PRç‡æ­£å¸¸ï¼Œé¡¹ç›®æœ‰è´¡çŒ®è€…ã€‚' if evidence['pr_rate'] == 0 else '**è¯´æ˜**: PRç‡ç•¥ä½ã€‚'}

### 3. Forkç‡åˆ†æ ({evidence['fork_rate']} åˆ†)

- **å®é™…å€¼**: {metrics['fork_rate']:.1f}%
- **æ­£å¸¸å€¼**: >8%
- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - Forkç‡è¿‡ä½' if evidence['fork_rate'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: Forkç‡<8%è¯´æ˜ç”¨æˆ·ä¸å®é™…ä½¿ç”¨é¡¹ç›®ï¼Œåªæ˜¯æ”¶è—ã€‚' if evidence['fork_rate'] > 0 else '**è¯´æ˜**: Forkç‡æ­£å¸¸ï¼Œç”¨æˆ·çœŸå®ä½¿ç”¨é¡¹ç›®ã€‚'}

### 4. Botæäº¤åˆ†æ ({evidence['bot_commits']} åˆ†)

- **å®é™…å€¼**: {metrics['bot_commit_ratio']:.0f}%
- **æ­£å¸¸å€¼**: <20%
- **åˆ¤å®š**: {'ğŸ”´ ä¸¥é‡å¼‚å¸¸ - Botåˆ·æ´»è·ƒåº¦' if evidence['bot_commits'] >= 30 else 'ğŸŸ¡ è½»åº¦å¼‚å¸¸' if evidence['bot_commits'] > 0 else 'ï¿½ï¿½ æ­£å¸¸'}

{'**è¯´æ˜**: Botæäº¤å æ¯”>80%ï¼Œæ˜æ˜¾ç”¨äºåˆ·æ´»è·ƒåº¦å’Œtrendingæ’åã€‚' if evidence['bot_commits'] >= 30 else '**è¯´æ˜**: æ— Botæäº¤ï¼Œæäº¤è®°å½•çœŸå®ã€‚' if evidence['bot_commits'] == 0 else '**è¯´æ˜**: å°‘é‡Botæäº¤ã€‚'}

### 5. æ—¶é—´èšç±»åˆ†æ ({evidence['time_clustering']} åˆ†) â­ æ ¸å¿ƒè¯æ®

"""

    if 'main_cluster' in metrics and metrics['main_cluster']:
        cluster = metrics['main_cluster']
        verdict_md += f"""
- **ä¸»ç°‡å¤§å°**: {cluster['count']} æ ·æœ¬ ({cluster['percentage']:.1f}%)
- **å¹³å‡é—´éš”**: {cluster['mean']:.1f} åˆ†é’Ÿ
- **æ ‡å‡†å·®**: {cluster['std']:.1f} åˆ†é’Ÿ
- **åˆ¤å®š**: {'ğŸ”´ æåº¦å¼‚å¸¸ - ç¨‹åºè‡ªåŠ¨åŒ–' if evidence['time_clustering'] >= 50 else 'ğŸŸ¡ è½»åº¦å¼‚å¸¸' if evidence['time_clustering'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**å…³é”®å‘ç°**: æ ‡å‡†å·®<5åˆ†é’Ÿï¼Œ44%çš„staré«˜åº¦é›†ä¸­ï¼è¿™åœ¨ç»Ÿè®¡å­¦ä¸Šä¸å¯èƒ½æ˜¯äººç±»è¡Œä¸ºï¼Œæ˜ç¡®æŒ‡å‘ç¨‹åºè‡ªåŠ¨åŒ–æ§åˆ¶ã€‚' if evidence['time_clustering'] >= 50 else '**è¯´æ˜**: æ—¶é—´åˆ†å¸ƒæ­£å¸¸ï¼Œç¬¦åˆäººç±»è¡Œä¸ºæ¨¡å¼ã€‚' if evidence['time_clustering'] == 0 else '**è¯´æ˜**: å­˜åœ¨ä¸€å®šè§„å¾‹æ€§ã€‚'}

**ç§‘å­¦ä¾æ®**:
- äººç±»è¡Œä¸ºçš„æ—¶é—´é—´éš”æ ‡å‡†å·®é€šå¸¸>50åˆ†é’Ÿ
- æ ‡å‡†å·®<10åˆ†é’Ÿå³ä¸ºå¯ç–‘
- æ ‡å‡†å·®<5åˆ†é’ŸåŸºæœ¬ç¡®å®šä¸ºç¨‹åºæ§åˆ¶
"""
    else:
        verdict_md += "\næ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œèšç±»åˆ†æã€‚\n"

    verdict_md += f"""
### 6. æ‰¹é‡åˆ›å»ºåˆ†æ ({evidence['bulk_creation']} åˆ†)

- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - å‘ç°æ‰¹é‡åˆ›å»º' if evidence['bulk_creation'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: å‘ç°å¤šä¸ªæ—¥æœŸå­˜åœ¨æ‰¹é‡åˆ›å»ºé«˜starä»“åº“çš„è¡Œä¸ºã€‚' if evidence['bulk_creation'] > 0 else '**è¯´æ˜**: æœªå‘ç°æ‰¹é‡åˆ›å»ºè¡Œä¸ºã€‚'}

---

## ğŸ“ˆ è¯„åˆ†è¯´æ˜

| åˆ†æ•°èŒƒå›´ | ç­‰çº§ | è¯´æ˜ |
|---------|------|------|
| 0-30 | ğŸŸ¢ ä½ | æ­£å¸¸é¡¹ç›®ï¼Œæ— æ˜æ˜¾å¼‚å¸¸ |
| 31-60 | ğŸŸ¡ ä¸­ | å­˜åœ¨éƒ¨åˆ†å¯ç–‘ç‰¹å¾ |
| 61-100 | ğŸ”´ é«˜ | é«˜åº¦å¯ç–‘ï¼Œå¯èƒ½å­˜åœ¨åˆ·é‡ |
| 100+ | ğŸ”´ æé«˜ | ç¡®è®¤åˆ·é‡ï¼Œè¯æ®ç¡®å‡¿ |

---

## ğŸ¯ æœ€ç»ˆç»“è®º

"""

    if total_score >= 100:
        verdict_md += f"""
### âš ï¸  ç¡®è®¤å­˜åœ¨Staræ“çºµè¡Œä¸º

åŸºäºå¤šç»´åº¦è¯æ®åˆ†æï¼Œè¯¥ä»“åº“å­˜åœ¨**æ˜ç¡®çš„Staræ“çºµè¡Œä¸º**ï¼š

#### æ ¸å¿ƒè¯æ®:
{'1. âœ… **æ—¶é—´èšç±»å¼‚å¸¸** - æ ‡å‡†å·®' + f"{metrics.get('main_cluster', {}).get('std', 0):.1f}" + 'åˆ†é’Ÿï¼Œç¨‹åºè‡ªåŠ¨åŒ–ç‰¹å¾æ˜æ˜¾' if evidence['time_clustering'] >= 50 else ''}
{'2. âœ… **Botåˆ·æ´»è·ƒåº¦** - ' + f"{metrics['bot_commit_ratio']:.0f}" + '%çš„æäº¤æ˜¯Bot' if evidence['bot_commits'] >= 30 else ''}
{'3. âœ… **Issue/PRç‡æä½** - å‡ ä¹æ— çœŸå®ç”¨æˆ·äº’åŠ¨' if evidence['issue_rate'] + evidence['pr_rate'] >= 40 else ''}
{'4. âœ… **Forkç‡è¿‡ä½** - ç”¨æˆ·ä¸å®é™…ä½¿ç”¨é¡¹ç›®' if evidence['fork_rate'] > 0 else ''}

#### å»ºè®®:
- å¯å‘GitHub Supportä¸¾æŠ¥
- æä¾›æœ¬åˆ†ææŠ¥å‘Šä½œä¸ºè¯æ®
- é™„ä¸Šå¯è§†åŒ–å›¾è¡¨
"""
    elif total_score >= 60:
        verdict_md += f"""
### âš ï¸  é«˜åº¦å¯ç–‘

è¯¥ä»“åº“å­˜åœ¨å¤šä¸ªå¼‚å¸¸æŒ‡æ ‡ï¼Œ**é«˜åº¦æ€€ç–‘å­˜åœ¨åˆ·é‡è¡Œä¸º**ã€‚

å»ºè®®è¿›ä¸€æ­¥è§‚å¯Ÿå¹¶æ”¶é›†æ›´å¤šè¯æ®ã€‚
"""
    elif total_score >= 30:
        verdict_md += f"""
### âš ï¸  ä¸­åº¦å¯ç–‘

å­˜åœ¨éƒ¨åˆ†å¼‚å¸¸æŒ‡æ ‡ï¼Œéœ€è¦æŒç»­å…³æ³¨ã€‚

å¯èƒ½æ˜¯æ¨å¹¿ç­–ç•¥å¯¼è‡´çš„éå…¸å‹å¢é•¿ï¼Œä½†ä¹Ÿä¸æ’é™¤è½»åº¦åˆ·é‡ã€‚
"""
    else:
        verdict_md += f"""
### âœ… æ­£å¸¸é¡¹ç›®

å„é¡¹æŒ‡æ ‡å‡åœ¨æ­£å¸¸èŒƒå›´å†…ï¼Œæœªå‘ç°æ˜æ˜¾çš„åˆ·é‡ç‰¹å¾ã€‚

è¯¥é¡¹ç›®çš„starå¢é•¿æ¨¡å¼ç¬¦åˆæ­£å¸¸çš„å¼€æºé¡¹ç›®è§„å¾‹ã€‚
"""

    verdict_md += f"""

---

## ğŸ“ æŠ€æœ¯è¯´æ˜

### åˆ†ææ–¹æ³•:
- **ç»Ÿè®¡å­¦**: scipyå±‚æ¬¡èšç±»ã€Z-scoreå¼‚å¸¸æ£€æµ‹
- **æ•°æ®æº**: GitHubå…¬å¼€API
- **æ ·æœ¬é‡**: å‰100ä¸ªstargazers
- **èšç±»æ–¹æ³•**: Wardå±‚æ¬¡èšç±»

### å‡†ç¡®æ€§:
- âœ… åŸºäºç§‘å­¦ç»Ÿè®¡æ–¹æ³•
- âœ… å¤šç»´åº¦äº¤å‰éªŒè¯
- âœ… çœŸå®é¡¹ç›®æµ‹è¯•éªŒè¯

### å±€é™æ€§:
- ä»…åˆ†æå…¬å¼€æ•°æ®
- éœ€è¦è¶³å¤Ÿçš„æ ·æœ¬é‡
- æ— æ³•æ£€æµ‹æ‰€æœ‰åˆ·é‡æ‰‹æ®µ

---

**ç”Ÿæˆå·¥å…·**: Star Manipulation Detector v2.0  
**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**æŠ¥å‘Šæ ¼å¼**: Markdown

---

## ğŸ“ é™„ä»¶

- è¯¦ç»†æ•°æ®: `report_{owner}_{repo}.json`
- å¯è§†åŒ–å›¾è¡¨: `visualization_{owner}_{repo}.png`

"""

    output_file = f"verdict_{owner}_{repo}.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(verdict_md)
    
    print(f"   âœ“ Saved: {output_file}")

def analyze_repository(owner, repo):
    """Main analysis function"""
    
    print("="*70)
    print("ğŸ” COMPREHENSIVE STAR MANIPULATION DETECTION")
    print("="*70)
    print(f"\nTarget: {owner}/{repo}")
    print(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # Get repository data
    print("[1/6] Fetching repository data...")
    repo_r = requests.get(f"https://api.github.com/repos/{owner}/{repo}", headers=HEADERS)
    if repo_r.status_code != 200:
        print(f"âŒ Error: Repository not found or API error ({repo_r.status_code})")
        sys.exit(1)
    
    repo_data = repo_r.json()
    stars = repo_data['stargazers_count']
    forks = repo_data['forks_count']
    
    # Use Search API to get accurate counts
    print("[2/6] Fetching issues and PRs (using Search API)...")
    total_issues = get_total_count_from_search(owner, repo, 'issue')
    total_prs = get_total_count_from_search(owner, repo, 'pr')
    
    # Calculate rates separately
    issue_rate = total_issues / stars * 100 if stars > 0 else 0
    pr_rate = total_prs / stars * 100 if stars > 0 else 0
    fork_rate = forks / stars * 100 if stars > 0 else 0
    
    print(f"   âœ“ Stars: {stars}")
    print(f"   âœ“ Forks: {forks} ({fork_rate:.1f}%)")
    print(f"   âœ“ Total Issues: {total_issues} ({issue_rate:.2f}%)")
    print(f"   âœ“ Total PRs: {total_prs} ({pr_rate:.2f}%)")
    
    # Evidence scoring
    evidence_1_score = 0
    if issue_rate < 1 and stars > 100:
        evidence_1_score = 30
        print(f"   ğŸ”´ ANOMALY: Issue rate < 1%")
    elif issue_rate < 2 and stars > 100:
        evidence_1_score = 15
        print(f"   ğŸŸ¡ WARNING: Issue rate < 2%")
    
    evidence_2_score = 0
    if pr_rate < 1 and stars > 100:
        evidence_2_score = 20
        print(f"   ğŸ”´ ANOMALY: PR rate < 1%")
    elif pr_rate < 2 and stars > 100:
        evidence_2_score = 10
        print(f"   ğŸŸ¡ WARNING: PR rate < 2%")
    
    evidence_3_score = 0
    if fork_rate < 8 and stars > 100:
        evidence_3_score = 25
        print(f"   ğŸ”´ ANOMALY: Fork rate < 8%")
    
    # Check bot commits
    print(f"\n[3/6] Analyzing commits...")
    commits_r = requests.get(
        f"https://api.github.com/repos/{owner}/{repo}/commits",
        headers=HEADERS, params={"per_page": 100}
    )
    commits = commits_r.json() if commits_r.status_code == 200 else []
    bot_commits = sum(1 for c in commits 
                     if 'Update TIME.md' in c.get('commit', {}).get('message', ''))
    bot_ratio = bot_commits / len(commits) * 100 if commits else 0
    
    print(f"   âœ“ Commits (sample): {len(commits)}")
    print(f"   âœ“ Bot Commits: {bot_commits} ({bot_ratio:.0f}%)")
    
    evidence_4_score = 0
    if bot_ratio > 80 and len(commits) > 50:
        evidence_4_score = 30
        print(f"   ğŸ”´ ANOMALY: Bot commits > 80%")
    elif bot_ratio > 50:
        evidence_4_score = 15
        print(f"   ğŸŸ¡ WARNING: Bot commits > 50%")
    
    # Time interval clustering
    print(f"\n[4/6] Performing time clustering analysis...")
    stargazers_r = requests.get(
        f"https://api.github.com/repos/{owner}/{repo}/stargazers",
        headers=STAR_HEADERS, params={"per_page": 100}
    )
    stargazers = stargazers_r.json() if stargazers_r.status_code == 200 else []
    
    evidence_5_score = 0
    main_cluster_info = {}
    
    if len(stargazers) >= 20:
        print(f"   âœ“ Analyzing {len(stargazers)} stargazers...")
        
        times = sorted([datetime.strptime(s['starred_at'], '%Y-%m-%dT%H:%M:%SZ') 
                       for s in stargazers])
        intervals = np.array([(times[i] - times[i-1]).total_seconds() 
                             for i in range(1, len(times))])
        
        intervals_min = intervals / 60
        X = intervals_min.reshape(-1, 1)
        
        linkage_matrix = linkage(X, method='ward')
        max_clusters = min(8, len(intervals) // 10)
        clusters = fcluster(linkage_matrix, t=max_clusters, criterion='maxclust')
        
        cluster_info = {}
        for cid in range(1, max_clusters + 1):
            cluster_data = intervals_min[clusters == cid]
            if len(cluster_data) > 0:
                cluster_info[cid] = {
                    'count': len(cluster_data),
                    'mean': float(np.mean(cluster_data)),
                    'std': float(np.std(cluster_data)),
                    'percentage': len(cluster_data) / len(intervals) * 100
                }
        
        sorted_clusters = sorted(cluster_info.items(), 
                                key=lambda x: x[1]['count'], reverse=True)
        main_cluster_info = sorted_clusters[0][1]
        
        print(f"   âœ“ Main cluster: {main_cluster_info['count']} samples, std={main_cluster_info['std']:.1f}min")
        
        if main_cluster_info['std'] < 5 and main_cluster_info['count'] >= 10:
            evidence_5_score = 50
            print(f"   ğŸ”´ CRITICAL: Automated pattern detected!")
        elif main_cluster_info['std'] < 10 and main_cluster_info['percentage'] > 30:
            evidence_5_score = 25
            print(f"   ğŸŸ¡ WARNING: Regular pattern")
    else:
        print(f"   âš ï¸  Insufficient data")
    
    # Check bulk creation
    print(f"\n[5/6] Checking repository patterns...")
    user_repos_r = requests.get(
        f"https://api.github.com/users/{owner}/repos",
        headers=HEADERS, params={"per_page": 100}
    )
    all_repos = user_repos_r.json() if user_repos_r.status_code == 200 else []
    
    high_star_repos = [r for r in all_repos if r['stargazers_count'] > 50]
    created_dates = defaultdict(list)
    
    for r in high_star_repos:
        date = r['created_at'][:10]
        created_dates[date].append(r['stargazers_count'])
    
    bulk_dates = {d: sum(s) for d, s in created_dates.items() if len(s) >= 2}
    
    evidence_6_score = 0
    if bulk_dates:
        print(f"   âœ“ Found {len(bulk_dates)} bulk creation dates")
        if any(len(s) >= 3 for s in created_dates.values()):
            evidence_6_score = 25
            print(f"   ğŸ”´ ANOMALY: Multiple repos/day")
        else:
            evidence_6_score = 10
    
    # Calculate total
    total_score = (evidence_1_score + evidence_2_score + evidence_3_score + 
                   evidence_4_score + evidence_5_score + evidence_6_score)
    
    print(f"\n[6/6] Saving report...")
    
    status = "ğŸ”´ HIGH SUSPICION" if total_score >= 80 else \
             "ğŸŸ¡ MEDIUM SUSPICION" if total_score >= 40 else \
             "ğŸŸ¢ LOW SUSPICION"
    
    report = {
        'analysis_date': datetime.now().isoformat(),
        'repository': f"{owner}/{repo}",
        'metrics': {
            'stars': stars,
            'forks': forks,
            'fork_rate': fork_rate,
            'total_issues': total_issues,
            'issue_rate': issue_rate,
            'total_prs': total_prs,
            'pr_rate': pr_rate,
            'bot_commit_ratio': bot_ratio,
            'main_cluster': main_cluster_info
        },
        'suspicion_score': total_score,
        'max_score': 180,
        'status': status,
        'evidence_scores': {
            'issue_rate': evidence_1_score,
            'pr_rate': evidence_2_score,
            'fork_rate': evidence_3_score,
            'bot_commits': evidence_4_score,
            'time_clustering': evidence_5_score,
            'bulk_creation': evidence_6_score
        }
    }
    
    output_file = f"report_{owner}_{repo}.json"
    with open(output_file, 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"   âœ“ Saved: {output_file}")
    
    # Generate visualization and verdict
    create_visualization(owner, repo, report)
    generate_verdict(owner, repo, report)
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š FINAL SCORE: {total_score}/180")
    print(f"STATUS: {status}")
    print('='*70)

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: python3 final.py <owner> <repo>")
        print("Example: python3 final.py XiaomingX indie-hacker-tools-plus")
        sys.exit(1)
    
    owner = sys.argv[1]
    repo = sys.argv[2]
    
    analyze_repository(owner, repo)

#!/usr/bin/env python3
"""
Comprehensive Star Manipulation Detection Tool
Usage: python3 final.py <owner> <repo>
"""
import sys
import os
import re
import requests
from datetime import datetime
from collections import Counter, defaultdict
import numpy as np
from scipy.cluster.hierarchy import linkage, fcluster
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import json
from dotenv import load_dotenv

load_dotenv()
TOKEN = os.getenv('GITHUB_TOKEN')
if not TOKEN:
    print("Error: GITHUB_TOKEN not found in .env file")
    sys.exit(1)

HEADERS = {"Authorization": f"token {TOKEN}"}
STAR_HEADERS = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3.star+json"}

def get_total_count_from_search(owner, repo, item_type):
    """Get accurate total count using GitHub Search API"""
    query = f"repo:{owner}/{repo} type:{item_type}"
    url = "https://api.github.com/search/issues"
    
    try:
        r = requests.get(url, headers=HEADERS, params={"q": query, "per_page": 1})
        if r.status_code == 200:
            return r.json().get('total_count', 0)
        else:
            return 0
    except:
        return 0

def create_visualization(owner, repo, report_data, stargazers_data, intervals_min, times, clusters, max_clusters):
    """Create 4-panel visualization"""
    print(f"\n[7/8] Creating visualization...")
    
    metrics = report_data['metrics']
    main_cluster = metrics.get('main_cluster', {})
    
    # Calculate half-hour peak
    star_minutes = [t.minute for t in times]
    near_half = sum(1 for m in star_minutes if 25 <= m <= 35)
    half_hour_pct = near_half / len(times) * 100
    
    # Filter data for plot 1: only show intervals < 500 minutes
    intervals_filtered = intervals_min[intervals_min < 500]
    in_range_count = len(intervals_filtered)
    total_count = len(intervals_min)
    in_range_pct = in_range_count / total_count * 100
    
    # Create figure
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle(f'Star Manipulation Evidence - {owner}/{repo}', 
                 fontsize=16, fontweight='bold')
    
    # Plot 1: Interval Distribution (< 500 min only)
    ax1 = axes[0, 0]
    ax1.hist(intervals_filtered, bins=30, color='steelblue', edgecolor='black', alpha=0.7)
    ax1.axvline(main_cluster['mean'], color='red', linestyle='--', linewidth=2,
               label=f"Main cluster: {main_cluster['mean']:.1f} min")
    ax1.set_xlabel('Time Interval (minutes)')
    ax1.set_ylabel('Frequency')
    ax1.set_title(f'Star Time Interval Distribution (<500 min)\n{in_range_count}/{total_count} stars ({in_range_pct:.1f}%) in this range')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Cluster Visualization
    ax2 = axes[0, 1]
    colors = plt.cm.Set3(np.linspace(0, 1, max_clusters))
    for cluster_id in range(1, max_clusters + 1):
        cluster_data = intervals_min[clusters == cluster_id]
        if len(cluster_data) > 0:
            ax2.scatter([cluster_id] * len(cluster_data), cluster_data, 
                       c=[colors[cluster_id-1]], alpha=0.6, s=50)
    ax2.set_xlabel('Cluster ID')
    ax2.set_ylabel('Interval (minutes)')
    ax2.set_title('Hierarchical Clustering Results')
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: Time of Day Distribution
    ax3 = axes[1, 0]
    hours = [t.hour for t in times]
    hour_counts = Counter(hours)
    ax3.bar(hour_counts.keys(), hour_counts.values(), color='coral', edgecolor='black')
    ax3.set_xlabel('Hour of Day')
    ax3.set_ylabel('Number of Stars')
    ax3.set_title('Star Distribution by Hour')
    ax3.set_xticks(range(24))
    ax3.grid(True, alpha=0.3, axis='y')
    
    # Plot 4: Key Metrics
    ax4 = axes[1, 1]
    ax4.axis('off')
    
    # Determine status indicators
    issue_status = "Suspicious: < 1%" if metrics['issue_rate'] < 1 else "OK"
    pr_status = "Suspicious: < 1%" if metrics['pr_rate'] < 1 else "OK"
    fork_status = "Suspicious: < 8%" if metrics['fork_rate'] < 8 else "OK"
    bot_status = "Suspicious: > 80%" if metrics['bot_commit_ratio'] > 80 else "OK"
    
    metrics_text = f"""
KEY EVIDENCE SUMMARY

Repository Stats:
â€¢ Total Stars: {metrics['stars']}
â€¢ Issue Rate: {metrics['issue_rate']:.2f}% ({issue_status})
â€¢ PR Rate: {metrics['pr_rate']:.2f}% ({pr_status})
â€¢ Fork Rate: {metrics['fork_rate']:.1f}% ({fork_status})
â€¢ Bot Commits: {metrics['bot_commit_ratio']:.0f}% ({bot_status})

Time Pattern Analysis:
â€¢ Main Cluster: {main_cluster['percentage']:.1f}%
â€¢ Mean Interval: {main_cluster['mean']:.1f} min
â€¢ Std Deviation: {main_cluster['std']:.1f} min
â€¢ Half-hour Peak: {half_hour_pct:.0f}%

Suspicion Score: {report_data['suspicion_score']}/{report_data['max_score']}
    """
    
    ax4.text(0.1, 0.5, metrics_text, fontsize=11, family='monospace',
            verticalalignment='center')
    
    plt.tight_layout()
    
    output_file = f"visualization_{owner}_{repo}.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   âœ“ Saved: {output_file}")
    plt.close()

def generate_verdict(owner, repo, report_data):
    """Generate detailed verdict markdown file"""
    print(f"\n[8/8] Generating verdict document...")
    
    metrics = report_data['metrics']
    evidence = report_data['evidence_scores']
    total_score = report_data['suspicion_score']
    
    # Determine verdict level
    if total_score >= 100:
        verdict_level = "ğŸ”´ CONFIRMED MANIPULATION"
        confidence = "æé«˜"
    elif total_score >= 60:
        verdict_level = "ğŸ”´ HIGH SUSPICION"
        confidence = "é«˜"
    elif total_score >= 30:
        verdict_level = "ğŸŸ¡ MEDIUM SUSPICION"
        confidence = "ä¸­"
    else:
        verdict_level = "ğŸŸ¢ LOW SUSPICION"
        confidence = "ä½"
    
    verdict_md = f"""# åˆ†ææŠ¥å‘Š - {owner}/{repo}

> **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ¯ æœ€ç»ˆåˆ¤å†³

### å¯ç–‘åº¦è¯„åˆ†: **{total_score}/{report_data['max_score']}**

### åˆ¤å®šç»“æœ: **{verdict_level}**

### ç½®ä¿¡åº¦: **{confidence}**

---

## ğŸ“Š åŸºç¡€æ•°æ®

| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |
|------|------|------|
| Stars | {metrics['stars']} | - |
| Forks | {metrics['forks']} ({metrics['fork_rate']:.1f}%) | {'ğŸ”´' if metrics['fork_rate'] < 8 else 'ğŸŸ¢'} |
| Issues | {metrics['total_issues']} ({metrics['issue_rate']:.2f}%) | {'ğŸ”´' if metrics['issue_rate'] < 2 else 'ğŸŸ¢'} |
| PRs | {metrics['total_prs']} ({metrics['pr_rate']:.2f}%) | {'ğŸ”´' if metrics['pr_rate'] < 2 else 'ğŸŸ¢'} |
| Bot Commits | {metrics['bot_commit_ratio']:.0f}% | {'ğŸ”´' if metrics['bot_commit_ratio'] > 50 else 'ğŸŸ¢'} |

---

## ğŸ” è¯æ®è¯¦æƒ…

### 1. Issueç‡åˆ†æ ({evidence['issue_rate']} åˆ†)

- **å®é™…å€¼**: {metrics['issue_rate']:.2f}%
- **æ­£å¸¸å€¼**: >2%
- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - Issueç‡è¿‡ä½' if evidence['issue_rate'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: Issueç‡<1%è¯´æ˜ç”¨æˆ·åªæ”¶è—ä¸ä½¿ç”¨ï¼Œå…¸å‹çš„è™šå‡starç‰¹å¾ã€‚' if evidence['issue_rate'] >= 30 else '**è¯´æ˜**: Issueç‡æ­£å¸¸ï¼Œç”¨æˆ·æœ‰çœŸå®åé¦ˆã€‚' if evidence['issue_rate'] == 0 else '**è¯´æ˜**: Issueç‡ç•¥ä½ï¼Œéœ€å…³æ³¨ã€‚'}

### 2. PRç‡åˆ†æ ({evidence['pr_rate']} åˆ†)

- **å®é™…å€¼**: {metrics['pr_rate']:.2f}%
- **æ­£å¸¸å€¼**: >2%
- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - PRç‡è¿‡ä½' if evidence['pr_rate'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: å‡ ä¹æ— PRè¯´æ˜é¡¹ç›®æ— äººè´¡çŒ®ï¼Œç¼ºä¹çœŸå®ç”¨æˆ·å‚ä¸ã€‚' if evidence['pr_rate'] >= 20 else '**è¯´æ˜**: PRç‡æ­£å¸¸ï¼Œé¡¹ç›®æœ‰è´¡çŒ®è€…ã€‚' if evidence['pr_rate'] == 0 else '**è¯´æ˜**: PRç‡ç•¥ä½ã€‚'}

### 3. Forkç‡åˆ†æ ({evidence['fork_rate']} åˆ†)

- **å®é™…å€¼**: {metrics['fork_rate']:.1f}%
- **æ­£å¸¸å€¼**: >8%
- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - Forkç‡è¿‡ä½' if evidence['fork_rate'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: Forkç‡<8%è¯´æ˜ç”¨æˆ·ä¸å®é™…ä½¿ç”¨é¡¹ç›®ï¼Œåªæ˜¯æ”¶è—ã€‚' if evidence['fork_rate'] > 0 else '**è¯´æ˜**: Forkç‡æ­£å¸¸ï¼Œç”¨æˆ·çœŸå®ä½¿ç”¨é¡¹ç›®ã€‚'}

### 4. Botæäº¤åˆ†æ ({evidence['bot_commits']} åˆ†)

- **å®é™…å€¼**: {metrics['bot_commit_ratio']:.0f}%
- **æ­£å¸¸å€¼**: <20%
- **åˆ¤å®š**: {'ğŸ”´ ä¸¥é‡å¼‚å¸¸ - Botåˆ·æ´»è·ƒåº¦' if evidence['bot_commits'] >= 30 else 'ğŸŸ¡ è½»åº¦å¼‚å¸¸' if evidence['bot_commits'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**è¯´æ˜**: Botæäº¤å æ¯”>80%ï¼Œæ˜æ˜¾ç”¨äºåˆ·æ´»è·ƒåº¦å’Œtrendingæ’åã€‚' if evidence['bot_commits'] >= 30 else '**è¯´æ˜**: æ— Botæäº¤ï¼Œæäº¤è®°å½•çœŸå®ã€‚' if evidence['bot_commits'] == 0 else '**è¯´æ˜**: å°‘é‡Botæäº¤ã€‚'}

### 5. æ—¶é—´èšç±»åˆ†æ ({evidence['time_clustering']} åˆ†) â­ æ ¸å¿ƒè¯æ®

"""

    if 'main_cluster' in metrics and metrics['main_cluster']:
        cluster = metrics['main_cluster']
        verdict_md += f"""
- **ä¸»ç°‡å¤§å°**: {cluster['count']} æ ·æœ¬ ({cluster['percentage']:.1f}%)
- **å¹³å‡é—´éš”**: {cluster['mean']:.1f} åˆ†é’Ÿ
- **æ ‡å‡†å·®**: {cluster['std']:.1f} åˆ†é’Ÿ
- **åˆ¤å®š**: {'ğŸ”´ æåº¦å¼‚å¸¸ - ç¨‹åºè‡ªåŠ¨åŒ–' if evidence['time_clustering'] >= 50 else 'ğŸŸ¡ è½»åº¦å¼‚å¸¸' if evidence['time_clustering'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

{'**å…³é”®å‘ç°**: æ ‡å‡†å·®<5åˆ†é’Ÿï¼Œ' + str(int(cluster['percentage'])) + '%çš„staré«˜åº¦é›†ä¸­ï¼è¿™åœ¨ç»Ÿè®¡å­¦ä¸Šä¸å¯èƒ½æ˜¯äººç±»è¡Œä¸ºï¼Œæ˜ç¡®æŒ‡å‘ç¨‹åºè‡ªåŠ¨åŒ–æ§åˆ¶ã€‚' if evidence['time_clustering'] >= 50 else '**è¯´æ˜**: æ—¶é—´åˆ†å¸ƒæ­£å¸¸ï¼Œç¬¦åˆäººç±»è¡Œä¸ºæ¨¡å¼ã€‚' if evidence['time_clustering'] == 0 else '**è¯´æ˜**: å­˜åœ¨ä¸€å®šè§„å¾‹æ€§ã€‚'}
"""
    else:
        verdict_md += "\næ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œèšç±»åˆ†æã€‚\n"

    verdict_md += f"""
### 6. æ‰¹é‡åˆ›å»ºåˆ†æ ({evidence['bulk_creation']} åˆ†)

- **åˆ¤å®š**: {'ğŸ”´ å¼‚å¸¸ - å‘ç°æ‰¹é‡åˆ›å»º' if evidence['bulk_creation'] > 0 else 'ğŸŸ¢ æ­£å¸¸'}

---

## ğŸ¯ æœ€ç»ˆç»“è®º

"""

    if total_score >= 100:
        verdict_md += f"""
### âš ï¸  ç¡®è®¤å­˜åœ¨Staræ“çºµè¡Œä¸º

åŸºäºå¤šç»´åº¦è¯æ®åˆ†æï¼Œè¯¥ä»“åº“å­˜åœ¨**æ˜ç¡®çš„Staræ“çºµè¡Œä¸º**ã€‚

#### å»ºè®®:
- å¯å‘GitHub Supportä¸¾æŠ¥
- æä¾›æœ¬åˆ†ææŠ¥å‘Šä½œä¸ºè¯æ®
"""
    elif total_score >= 60:
        verdict_md += "### âš ï¸  é«˜åº¦å¯ç–‘\n\nè¯¥ä»“åº“å­˜åœ¨å¤šä¸ªå¼‚å¸¸æŒ‡æ ‡ã€‚\n"
    elif total_score >= 30:
        verdict_md += "### âš ï¸  ä¸­åº¦å¯ç–‘\n\nå­˜åœ¨éƒ¨åˆ†å¼‚å¸¸æŒ‡æ ‡ã€‚\n"
    else:
        verdict_md += "### âœ… æ­£å¸¸é¡¹ç›®\n\nå„é¡¹æŒ‡æ ‡å‡åœ¨æ­£å¸¸èŒƒå›´å†…ã€‚\n"

    verdict_md += f"""
---

**ç”Ÿæˆå·¥å…·**: https://github.com/zly2006/fake-star-detector# v2.0  
**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**æŠ¥å‘Šæ ¼å¼**: Markdown

---

## ğŸ“ é™„ä»¶

- è¯¦ç»†æ•°æ®: `report_{owner}_{repo}.json`
- å¯è§†åŒ–å›¾è¡¨: ![visualization](visualization_{owner}_{repo}.png)
"""

    output_file = f"verdict_{owner}_{repo}.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(verdict_md)
    
    print(f"   âœ“ Saved: {output_file}")

def analyze_repository(owner, repo):
    """Main analysis function"""
    
    print("="*70)
    print("ğŸ” COMPREHENSIVE STAR MANIPULATION DETECTION")
    print("="*70)
    print(f"\nTarget: {owner}/{repo}")
    print(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # Get repository data
    print("[1/6] Fetching repository data...")
    repo_r = requests.get(f"https://api.github.com/repos/{owner}/{repo}", headers=HEADERS)
    if repo_r.status_code != 200:
        print(f"âŒ Error: Repository not found ({repo_r.status_code})")
        sys.exit(1)
    
    repo_data = repo_r.json()
    stars = repo_data['stargazers_count']
    forks = repo_data['forks_count']
    
    # Get counts via Search API
    print("[2/6] Fetching issues and PRs...")
    total_issues = get_total_count_from_search(owner, repo, 'issue')
    total_prs = get_total_count_from_search(owner, repo, 'pr')
    
    issue_rate = total_issues / stars * 100 if stars > 0 else 0
    pr_rate = total_prs / stars * 100 if stars > 0 else 0
    fork_rate = forks / stars * 100 if stars > 0 else 0
    
    print(f"   âœ“ Stars: {stars}")
    print(f"   âœ“ Forks: {forks} ({fork_rate:.1f}%)")
    print(f"   âœ“ Issues: {total_issues} ({issue_rate:.2f}%)")
    print(f"   âœ“ PRs: {total_prs} ({pr_rate:.2f}%)")
    
    # Evidence scoring
    evidence_1_score = 30 if issue_rate < 1 and stars > 100 else (15 if issue_rate < 2 and stars > 100 else 0)
    evidence_2_score = 20 if pr_rate < 1 and stars > 100 else (10 if pr_rate < 2 and stars > 100 else 0)
    evidence_3_score = 25 if fork_rate < 8 and stars > 100 else 0
    
    if evidence_1_score >= 30: print(f"   ğŸ”´ ANOMALY: Issue rate < 1%")
    if evidence_2_score >= 20: print(f"   ğŸ”´ ANOMALY: PR rate < 1%")
    if evidence_3_score > 0: print(f"   ğŸ”´ ANOMALY: Fork rate < 8%")
    
    # Commits
    print(f"\n[3/6] Analyzing commits...")
    commits_r = requests.get(f"https://api.github.com/repos/{owner}/{repo}/commits",
                            headers=HEADERS, params={"per_page": 100})
    commits = commits_r.json() if commits_r.status_code == 200 else []
    bot_commits = sum(1 for c in commits if 'Update TIME.md' in c.get('commit', {}).get('message', ''))
    bot_ratio = bot_commits / len(commits) * 100 if commits else 0
    
    print(f"   âœ“ Commits: {len(commits)}, Bot: {bot_commits} ({bot_ratio:.0f}%)")
    
    evidence_4_score = 30 if bot_ratio > 80 and len(commits) > 50 else (15 if bot_ratio > 50 else 0)
    if evidence_4_score >= 30: print(f"   ğŸ”´ ANOMALY: Bot commits > 80%")
    
    # Clustering
    print(f"\n[4/6] Time clustering analysis...")
    stargazers_r = requests.get(f"https://api.github.com/repos/{owner}/{repo}/stargazers",
                                headers=STAR_HEADERS, params={"per_page": 100})
    stargazers = stargazers_r.json() if stargazers_r.status_code == 200 else []
    
    evidence_5_score = 0
    main_cluster_info = {}
    intervals_min = None
    times = None
    clusters = None
    max_clusters = 0
    
    if len(stargazers) >= 20:
        times = sorted([datetime.strptime(s['starred_at'], '%Y-%m-%dT%H:%M:%SZ') for s in stargazers])
        intervals = np.array([(times[i] - times[i-1]).total_seconds() for i in range(1, len(times))])
        intervals_min = intervals / 60
        
        X = intervals_min.reshape(-1, 1)
        linkage_matrix = linkage(X, method='ward')
        max_clusters = min(8, len(intervals) // 10)
        clusters = fcluster(linkage_matrix, t=max_clusters, criterion='maxclust')
        
        cluster_info = {}
        for cid in range(1, max_clusters + 1):
            cluster_data = intervals_min[clusters == cid]
            if len(cluster_data) > 0:
                cluster_info[cid] = {
                    'count': len(cluster_data),
                    'mean': float(np.mean(cluster_data)),
                    'std': float(np.std(cluster_data)),
                    'percentage': len(cluster_data) / len(intervals) * 100
                }
        
        sorted_clusters = sorted(cluster_info.items(), key=lambda x: x[1]['count'], reverse=True)
        main_cluster_info = sorted_clusters[0][1]
        
        print(f"   âœ“ Main cluster: {main_cluster_info['count']} samples, std={main_cluster_info['std']:.1f}min")
        
        if main_cluster_info['std'] < 5 and main_cluster_info['count'] >= 10:
            evidence_5_score = 50
            print(f"   ğŸ”´ CRITICAL: Automated pattern!")
        elif main_cluster_info['std'] < 10 and main_cluster_info['percentage'] > 30:
            evidence_5_score = 25
    else:
        print(f"   âš ï¸  Insufficient data")
    
    # Bulk creation
    print(f"\n[5/6] Checking patterns...")
    user_repos_r = requests.get(f"https://api.github.com/users/{owner}/repos",
                                headers=HEADERS, params={"per_page": 100})
    all_repos = user_repos_r.json() if user_repos_r.status_code == 200 else []
    
    high_star_repos = [r for r in all_repos if r['stargazers_count'] > 50]
    created_dates = defaultdict(list)
    for r in high_star_repos:
        created_dates[r['created_at'][:10]].append(r['stargazers_count'])
    
    bulk_dates = {d: sum(s) for d, s in created_dates.items() if len(s) >= 2}
    evidence_6_score = 25 if any(len(s) >= 3 for s in created_dates.values()) else (10 if bulk_dates else 0)
    
    if evidence_6_score > 0:
        print(f"   âœ“ Found {len(bulk_dates)} bulk dates")
    
    # Total
    total_score = sum([evidence_1_score, evidence_2_score, evidence_3_score, 
                      evidence_4_score, evidence_5_score, evidence_6_score])
    
    print(f"\n[6/6] Saving report...")
    
    status = "ğŸ”´ HIGH SUSPICION" if total_score >= 80 else \
             "ğŸŸ¡ MEDIUM SUSPICION" if total_score >= 40 else \
             "ğŸŸ¢ LOW SUSPICION"
    
    report = {
        'analysis_date': datetime.now().isoformat(),
        'repository': f"{owner}/{repo}",
        'metrics': {
            'stars': stars, 'forks': forks, 'fork_rate': fork_rate,
            'total_issues': total_issues, 'issue_rate': issue_rate,
            'total_prs': total_prs, 'pr_rate': pr_rate,
            'bot_commit_ratio': bot_ratio,
            'main_cluster': main_cluster_info
        },
        'suspicion_score': total_score,
        'max_score': 180,
        'status': status,
        'evidence_scores': {
            'issue_rate': evidence_1_score,
            'pr_rate': evidence_2_score,
            'fork_rate': evidence_3_score,
            'bot_commits': evidence_4_score,
            'time_clustering': evidence_5_score,
            'bulk_creation': evidence_6_score
        }
    }
    
    output_file = f"report_{owner}_{repo}.json"
    with open(output_file, 'w') as f:
        json.dump(report, f, indent=2)
    print(f"   âœ“ Saved: {output_file}")
    
    # Visualization
    if intervals_min is not None and times is not None:
        create_visualization(owner, repo, report, stargazers, intervals_min, times, clusters, max_clusters)
    
    # Verdict
    generate_verdict(owner, repo, report)
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š FINAL SCORE: {total_score}/180")
    print(f"STATUS: {status}")
    print('='*70)

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: python3 final.py <owner> <repo>")
        sys.exit(1)
    
    analyze_repository(sys.argv[1], sys.argv[2])

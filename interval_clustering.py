#!/usr/bin/env python3
"""
ä½¿ç”¨scipyè¿›è¡Œæ—¶é—´é—´éš”èšç±»åˆ†æ
"""
import requests
from datetime import datetime
import numpy as np
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.stats import zscore
from collections import Counter
import json

TOKEN = "ghp_xxx"
HEADERS = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github.v3.star+json"}

print("â±ï¸  ç§‘å­¦èšç±»åˆ†æ - ä½¿ç”¨scipy\n")

# è·å–å‰100ä¸ªstar
response = requests.get(
    "https://api.github.com/repos/XiaomingX/indie-hacker-tools-plus/stargazers",
    headers=HEADERS, params={"per_page": 100}
)
stars = response.json()

# æå–æ—¶é—´å¹¶è®¡ç®—é—´éš”
times = sorted([datetime.strptime(s['starred_at'], '%Y-%m-%dT%H:%M:%SZ') for s in stars])
intervals = np.array([(times[i] - times[i-1]).total_seconds() for i in range(1, len(times))])

print(f"âœ… åˆ†æ {len(intervals)} ä¸ªæ—¶é—´é—´éš”\n")

print("="*70)
print("ğŸ“Š å±‚æ¬¡èšç±»åˆ†æ")
print("="*70)

# è½¬æ¢ä¸ºåˆ†é’Ÿå¹¶reshapeä¸º2D
intervals_min = intervals / 60
X = intervals_min.reshape(-1, 1)

# å±‚æ¬¡èšç±»
linkage_matrix = linkage(X, method='ward')

# æ ¹æ®è·ç¦»é˜ˆå€¼åˆ‡åˆ†ä¸ºç°‡ï¼ˆå°è¯•åˆ†æˆ5-8ä¸ªç°‡ï¼‰
max_clusters = min(8, len(intervals) // 10)
clusters = fcluster(linkage_matrix, t=max_clusters, criterion='maxclust')

# åˆ†ææ¯ä¸ªç°‡
cluster_info = {}
for cluster_id in range(1, max_clusters + 1):
    cluster_data = intervals_min[clusters == cluster_id]
    if len(cluster_data) > 0:
        cluster_info[cluster_id] = {
            'count': len(cluster_data),
            'mean': float(np.mean(cluster_data)),
            'std': float(np.std(cluster_data)),
            'min': float(np.min(cluster_data)),
            'max': float(np.max(cluster_data))
        }

# æŒ‰æ•°é‡æ’åº
sorted_clusters = sorted(cluster_info.items(), key=lambda x: x[1]['count'], reverse=True)

print(f"\nè¯†åˆ«å‡º {len(cluster_info)} ä¸ªç°‡:\n")
for cluster_id, info in sorted_clusters:
    print(f"ç°‡ {cluster_id}:")
    print(f"   æ ·æœ¬æ•°: {info['count']} ({info['count']/len(intervals)*100:.1f}%)")
    print(f"   ä¸­å¿ƒ: {info['mean']:.1f}åˆ†é’Ÿ")
    print(f"   èŒƒå›´: {info['min']:.1f} - {info['max']:.1f}åˆ†é’Ÿ")
    print(f"   æ ‡å‡†å·®: {info['std']:.1f}")
    
    # åˆ¤æ–­æ˜¯å¦æ˜¯å›ºå®šé—´éš”
    if info['std'] < 5 and info['count'] >= 5:
        print(f"   ğŸ”´ é«˜åº¦è§„å¾‹ï¼ç–‘ä¼¼è‡ªåŠ¨åŒ–")
    elif info['std'] < 10 and info['count'] >= 3:
        print(f"   ğŸŸ¡ è¾ƒä¸ºè§„å¾‹")
    print()

# Z-scoreå¼‚å¸¸æ£€æµ‹
print("="*70)
print("ğŸ“ˆ å¼‚å¸¸å€¼æ£€æµ‹ (Z-score)")
print("="*70)

z_scores = np.abs(zscore(intervals_min))
outliers = np.where(z_scores > 2)[0]

print(f"\nå¼‚å¸¸å€¼æ•°é‡: {len(outliers)}/{len(intervals)} ({len(outliers)/len(intervals)*100:.1f}%)")
if len(outliers) > 0:
    print(f"å¼‚å¸¸é—´éš”(åˆ†é’Ÿ): {[f'{intervals_min[i]:.0f}' for i in outliers[:5]]}")

# æ£€æµ‹å‘¨æœŸæ€§ï¼ˆè‡ªç›¸å…³ï¼‰
print(f"\n{'='*70}")
print("ğŸ”„ å‘¨æœŸæ€§æ£€æµ‹")
print("="*70)

# æ£€æŸ¥ç‰¹å®šæ—¶é—´ç‚¹çš„é›†ä¸­åº¦
star_hours = [t.hour for t in times]
star_minutes = [t.minute for t in times]

hour_counter = Counter(star_hours)
most_common_hours = hour_counter.most_common(5)

print(f"\næœ€é›†ä¸­çš„å°æ—¶:")
for hour, count in most_common_hours:
    print(f"   {hour:02d}:00 - {count}æ¬¡ ({count/len(times)*100:.1f}%)")
    if count > len(times) * 0.15:
        print(f"      ğŸ”´ é›†ä¸­åº¦>15%ï¼Œç–‘ä¼¼å®šæ—¶ä»»åŠ¡")

# æ£€æŸ¥æ•´ç‚¹åˆ†é’Ÿåˆ†å¸ƒ
minute_ranges = {
    'æ•´ç‚¹(0-5åˆ†)': sum(1 for m in star_minutes if 0 <= m <= 5),
    'åŠç‚¹(25-35åˆ†)': sum(1 for m in star_minutes if 25 <= m <= 35),
}

print(f"\næ—¶é—´ç‚¹åˆ†å¸ƒ:")
for range_name, count in minute_ranges.items():
    pct = count / len(star_minutes) * 100
    print(f"   {range_name}: {count}æ¬¡ ({pct:.1f}%)")
    if pct > 20:
        print(f"      ğŸ”´ é«˜åº¦é›†ä¸­ï¼Œç–‘ä¼¼ç¨‹åºæ§åˆ¶")

# ç»¼åˆåˆ¤æ–­
print(f"\n{'='*70}")
print("ğŸ¯ è‡ªåŠ¨åŒ–ç¨‹åº¦è¯„ä¼°")
print("="*70)

score = 0
evidence = []

# æ£€æŸ¥ä¸»è¦ç°‡çš„è§„å¾‹æ€§
if sorted_clusters:
    main_cluster = sorted_clusters[0][1]
    if main_cluster['std'] < 5 and main_cluster['count'] >= 5:
        score += 40
        evidence.append(f"ä¸»ç°‡æ ‡å‡†å·®<5åˆ†é’Ÿï¼Œé«˜åº¦è§„å¾‹({main_cluster['count']}ä¸ªæ ·æœ¬)")
    elif main_cluster['std'] < 10:
        score += 20
        evidence.append(f"ä¸»ç°‡æ ‡å‡†å·®<10åˆ†é’Ÿï¼Œè¾ƒä¸ºè§„å¾‹")

# æ£€æŸ¥æ•´ç‚¹é›†ä¸­åº¦
if minute_ranges['æ•´ç‚¹(0-5åˆ†)'] / len(star_minutes) > 0.2:
    score += 30
    evidence.append(f"æ•´ç‚¹é™„è¿‘é›†ä¸­åº¦{minute_ranges['æ•´ç‚¹(0-5åˆ†)']/len(star_minutes)*100:.0f}%")

# æ£€æŸ¥å°æ—¶é›†ä¸­åº¦
if most_common_hours[0][1] > len(times) * 0.15:
    score += 20
    evidence.append(f"{most_common_hours[0][0]}æ—¶é›†ä¸­åº¦{most_common_hours[0][1]/len(times)*100:.0f}%")

# æ£€æŸ¥ç°‡çš„æ•°é‡ï¼ˆå¦‚æœç°‡å¾ˆå°‘è¯´æ˜æ¨¡å¼å•ä¸€ï¼‰
if len(cluster_info) <= 3:
    score += 10
    evidence.append(f"ä»…{len(cluster_info)}ä¸ªä¸»è¦æ¨¡å¼ï¼Œè¡Œä¸ºå•ä¸€")

print(f"\nè‡ªåŠ¨åŒ–å¯ç–‘åº¦: {score}/100\n")

if evidence:
    print("è¯æ®:")
    for e in evidence:
        print(f"   â€¢ {e}")
    print()

if score >= 70:
    print("ğŸ”´ ç»“è®º: é«˜åº¦ç–‘ä¼¼ç¨‹åºè‡ªåŠ¨åŒ–åˆ·star")
elif score >= 50:
    print("ğŸŸ¡ ç»“è®º: å­˜åœ¨æ˜æ˜¾è‡ªåŠ¨åŒ–ç‰¹å¾")
else:
    print("ğŸŸ¢ ç»“è®º: è‡ªåŠ¨åŒ–ç‰¹å¾ä¸æ˜æ˜¾")

# ä¿å­˜è¯¦ç»†ç»“æœ
result = {
    'clusters': {str(k): v for k, v in cluster_info.items()},
    'automation_score': score,
    'evidence': evidence,
    'outliers_count': len(outliers),
    'total_intervals': len(intervals)
}

with open('clustering_result.json', 'w') as f:
    json.dump(result, f, indent=2)

print(f"\nâœ… è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° clustering_result.json")
print("="*70)
